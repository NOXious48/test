{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>**Problem statement 1**</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1=pd.read_csv('iris_train.csv')          # reading the train set\n",
    "data_2=pd.read_csv('iris_test.csv')           # reading test set\n",
    "true_classes_1=np.array(data_1['Species'])    # train set Classes\n",
    "true_classes_2=np.array(data_2['Species'])    # test set Classes\n",
    "data_1=data_1.drop(data_1.columns[0], axis=1)\n",
    "data_2=data_2.drop(data_2.columns[0], axis=1)\n",
    "att_data_1=data_1.drop(['Species'],axis=1)    # train feature data\n",
    "att_data_2=data_2.drop(['Species'],axis=1)    # test Features data\n",
    "columns_list=list(att_data_1.columns)         # features list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Applying PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reduced_data(data,type=list):\n",
    "    sum_list=sum(data)\n",
    "    len_list=len(data)\n",
    "    mean_list=sum_list/len_list\n",
    "    list_1=[]\n",
    "    for i in data:\n",
    "        j=i-mean_list\n",
    "        list_1.append(j)\n",
    "    return list_1\n",
    "\n",
    "def reduction(data):\n",
    "# this is the data which has a mean value of 0 for all attributes\n",
    "    msd=pd.DataFrame(columns=columns_list)\n",
    "    for j in columns_list:                               # This loop will give the mean subtracted data\n",
    "        reduced_feature=list(mean_reduced_data(data[j]))\n",
    "        msd[j]=reduced_feature\n",
    "    return msd\n",
    "\n",
    "mean_sub_train_data=reduction(att_data_1)\n",
    "mean_sub_test_data=reduction(att_data_2)\n",
    "\n",
    "# transpose of mean subtrated data matrix\n",
    "msd_train_transpose=mean_sub_train_data.transpose()  \n",
    "msd_test_transpose=mean_sub_test_data.transpose()  \n",
    "\n",
    "def correlation_matrix(data1,data2):        # data1 is mean subtracted data and data 2 is its transpoase\n",
    "\n",
    "    # caluculating corelation matrix\n",
    "    array_1=data1.to_numpy()\n",
    "    array_2=data2.to_numpy()\n",
    "    covariance_matrix= np.matmul(array_2, array_1)\n",
    "    return covariance_matrix\n",
    "\n",
    "train_corr_matrix=correlation_matrix(mean_sub_train_data,msd_train_transpose)\n",
    "test_corr_matrix=correlation_matrix(mean_sub_test_data,msd_test_transpose)\n",
    " \n",
    "def PCA(data1,data2):              # data1 is covariance matrix,data2 is mean subtracted data\n",
    "\n",
    "    # eigen analysis\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(data1)      # a column is a eigen vector\n",
    "    sel_vectors=eigenvectors[:,0:1].T\n",
    "\n",
    "    # projection of data from corrected data\n",
    "    array_3=data2.to_numpy()\n",
    "    projected_data=np.dot(array_3,sel_vectors.T)\n",
    "\n",
    "    # converting array to dataframe for better representaion\n",
    "    reduced_data= pd.DataFrame(projected_data, columns=[\"PC1\"])    # finale data\n",
    "    return reduced_data,sel_vectors\n",
    "\n",
    "PC_train,sel_vector_1=PCA(train_corr_matrix,mean_sub_train_data)    # train set (reduced data),selected eigenvectors\n",
    "PC_test,sel_vector_2=PCA(test_corr_matrix,mean_sub_test_data)       # test set (reduced data),selected eigenvectors\n",
    "PC_train['Class']=true_classes_1\n",
    "PC_test['Class']=true_classes_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calculating gaussian parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Iris-setosa': {'mean': np.float64(-2.614563160523108), 'variance': np.float64(0.05112070782562285)}, 'Iris-versicolor': {'mean': np.float64(0.5549893709957102), 'variance': np.float64(0.36819932401753164)}, 'Iris-virginica': {'mean': np.float64(2.0981528771820557), 'variance': np.float64(0.48466890188260164)}}\n"
     ]
    }
   ],
   "source": [
    "train_data = PC_train \n",
    "# Get unique classes\n",
    "classes = train_data['Class'].unique()\n",
    "\n",
    "# Dictionary to store class-wise parameters\n",
    "gaussian_params = {}\n",
    "\n",
    "for c in classes:    # this loop will store the mean and variance of each class from train set\n",
    "    class_data = train_data[train_data['Class'] == c]['PC1']\n",
    "    '''print(c)\n",
    "    print(class_data)'''\n",
    "    mean = np.mean(class_data)\n",
    "    variance = np.var(class_data)\n",
    "    gaussian_params[c] = {'mean': mean, 'variance': variance}\n",
    "\n",
    "print(gaussian_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Applying baye's classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PC1            Class  Predicted_Class\n",
      "0   0.734116  Iris-versicolor  Iris-versicolor\n",
      "1  -2.370212      Iris-setosa      Iris-setosa\n",
      "2   3.611909   Iris-virginica   Iris-virginica\n",
      "3   0.629719  Iris-versicolor  Iris-versicolor\n",
      "4   1.148342  Iris-versicolor  Iris-versicolor\n",
      "5  -2.586089      Iris-setosa      Iris-setosa\n",
      "6  -0.357435  Iris-versicolor  Iris-versicolor\n",
      "7   1.749157   Iris-virginica   Iris-virginica\n",
      "8   0.751433  Iris-versicolor  Iris-versicolor\n",
      "9  -0.051086  Iris-versicolor  Iris-versicolor\n",
      "10  1.486336   Iris-virginica   Iris-virginica\n",
      "11 -2.972558      Iris-setosa      Iris-setosa\n",
      "12 -2.800284      Iris-setosa      Iris-setosa\n",
      "13 -2.857652      Iris-setosa      Iris-setosa\n",
      "14 -2.760069      Iris-setosa      Iris-setosa\n",
      "15  0.918746  Iris-versicolor  Iris-versicolor\n",
      "16  2.170605   Iris-virginica   Iris-virginica\n",
      "17 -0.146838  Iris-versicolor  Iris-versicolor\n",
      "18  0.453908  Iris-versicolor  Iris-versicolor\n",
      "19  1.977330   Iris-virginica   Iris-virginica\n",
      "20 -2.815783      Iris-setosa      Iris-setosa\n",
      "21  1.110301   Iris-virginica  Iris-versicolor\n",
      "22 -2.646919      Iris-setosa      Iris-setosa\n",
      "23  1.940755   Iris-virginica   Iris-virginica\n",
      "24  3.065290   Iris-virginica   Iris-virginica\n",
      "25  1.768349   Iris-virginica   Iris-virginica\n",
      "26  2.132123   Iris-virginica   Iris-virginica\n",
      "27  2.388211   Iris-virginica   Iris-virginica\n",
      "28 -2.899409      Iris-setosa      Iris-setosa\n",
      "29 -2.772297      Iris-setosa      Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "prior_probabilities = {}\n",
    "total_samples = len(train_data)\n",
    "\n",
    "# calculating probability of class\n",
    "for class_label in classes:\n",
    "    prior_probabilities[class_label] = len(train_data[train_data['Class'] == class_label]) / total_samples \n",
    "\n",
    "\n",
    "# Gaussian likelihood function\n",
    "def gaussian_likelihood(x, mean, variance):\n",
    "    return (1 / math.sqrt(2 * math.pi * variance)) * math.exp(-((x - mean) ** 2) / (2 * variance))\n",
    "\n",
    "# Classify each test sample\n",
    "test_data = PC_test\n",
    "predictions = []\n",
    "\n",
    "for _, row in test_data.iterrows():     # _ is row index and row is data of each column in that row\n",
    "    sample = row['PC1']\n",
    "    #print(row)\n",
    "    max_posterior = -float('inf')\n",
    "    predicted_class = None\n",
    "\n",
    "    for c, params in gaussian_params.items():    # c is key and params are value\n",
    "        likelihood = gaussian_likelihood(sample, params['mean'], params['variance'])\n",
    "        posterior = likelihood * prior_probabilities[c]\n",
    "        if posterior > max_posterior:\n",
    "            max_posterior = posterior\n",
    "            predicted_class = c\n",
    "\n",
    "    predictions.append(predicted_class)\n",
    "\n",
    "test_data['Predicted_Class'] = predictions\n",
    "print(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(true_labels, predicted_labels, class_labels):\n",
    "    # Initialize the confusion matrix with zeros\n",
    "    matrix = np.zeros((len(class_labels), len(class_labels)), dtype=int)\n",
    "    \n",
    "    # Map class labels to indices for matrix positioning\n",
    "    label_to_index = {label: i for i, label in enumerate(class_labels)}\n",
    "    \n",
    "    # Fill the confusion matrix\n",
    "    for true_label, predicted_label in zip(true_labels, predicted_labels):\n",
    "        true_index = label_to_index[true_label]\n",
    "        predicted_index = label_to_index[predicted_label]\n",
    "        matrix[true_index, predicted_index] += 1\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def accuracy(true_labels, predicted_labels):\n",
    "\n",
    "    correct_predictions = sum(t == p for t, p in zip(true_labels, predicted_labels))\n",
    "    total_samples = len(true_labels)\n",
    "    return (correct_predictions / total_samples) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "Iris-setosa               10                0               0\n",
      "Iris-versicolor            0                9               0\n",
      "Iris-virginica             0                1              10\n",
      "Accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "confu_matrix = confusion_matrix(test_data['Class'], test_data['Predicted_Class'],classes)\n",
    "confusion_daf = pd.DataFrame(confu_matrix, index=classes, columns=classes)\n",
    "print(confusion_daf)\n",
    "\"\"\"row are actual classes and columns are predicted classes\"\"\"\n",
    "accuracy_score_1 = accuracy(test_data['Class'], test_data['Predicted_Class'])\n",
    "print(f\"Accuracy: {accuracy_score_1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>**Problem statement 2**</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "Iris-setosa               10                0               0\n",
      "Iris-versicolor            0                8               1\n",
      "Iris-virginica             0                0              11\n",
      "Accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Estimate the parameters (mean vector and covariance matrix) for each class\n",
    "gaussian_params = {}  # Store mean and covariance for each class\n",
    "prior_probabilities = {}\n",
    "\n",
    "train_data=data_1\n",
    "test_data=data_2\n",
    "classes = train_data['Species'].unique()\n",
    "total_samples = len(train_data)\n",
    "\n",
    "for class_label in classes:\n",
    "    class_data = train_data[train_data['Species'] == class_label].drop('Species', axis=1)  # Drop class column to keep features\n",
    "    mean_vector = class_data.mean(axis=0).values  # Mean of each feature\n",
    "    covariance_matrix = np.cov(class_data.T)  # Covariance matrix\n",
    "    gaussian_params[class_label] = {'mean': mean_vector, 'covariance': covariance_matrix}\n",
    "    \n",
    "    # Calculate prior probabilities\n",
    "    prior_probabilities[class_label] = len(class_data) / total_samples\n",
    "\n",
    "# Classify each test sample based on likelihood and prior\n",
    "predictions = []\n",
    "\n",
    "\n",
    "for _, row in test_data.iterrows():\n",
    "    sample = row.drop('Species').values  # Get the four-dimensional test sample (without the class label)\n",
    "    max_posterior = -float('inf')\n",
    "    predicted_class = None\n",
    "    \n",
    "    for class_label, params in gaussian_params.items():\n",
    "        # Likelihood calculation using scipy.stats.multivariate_normal\n",
    "        likelihood = multivariate_normal.pdf(sample, mean=params['mean'], cov=params['covariance'])\n",
    "        \n",
    "        # Multiply the likelihood by the prior probability\n",
    "        posterior = likelihood * prior_probabilities[class_label]\n",
    "        \n",
    "        # Find the class with the highest posterior\n",
    "        if posterior > max_posterior:\n",
    "            max_posterior = posterior\n",
    "            predicted_class = class_label\n",
    "    \n",
    "    # Store the predicted class\n",
    "    predictions.append(predicted_class)\n",
    "\n",
    "# Evaluate the model\n",
    "true_labels = test_data['Species'].values\n",
    "conf_matrix = confusion_matrix(true_labels, predictions,classes)\n",
    "confusion_df = pd.DataFrame(conf_matrix, index=classes, columns=classes)\n",
    "accuracy_score_2 = accuracy(true_labels, predictions)\n",
    "# Print the confusion matrix and accuracy\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_df)\n",
    "print(f\"Accuracy: {accuracy_score_2 * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "Iris-setosa               10                0               0\n",
      "Iris-versicolor            0                8               1\n",
      "Iris-virginica             0                0              11\n",
      "Accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "# Estimate the parameters (mean vector and covariance matrix) for each class\n",
    "gaussian_params = {}  # Store mean and covariance for each class\n",
    "prior_probabilities = {}\n",
    "\n",
    "train_data = data_1\n",
    "test_data = data_2\n",
    "classes = train_data['Species'].unique()\n",
    "total_samples = len(train_data)\n",
    "\n",
    "for class_label in classes:\n",
    "    class_data = train_data[train_data['Species'] == class_label].drop('Species', axis=1)\n",
    "\n",
    "    class_data = class_data.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    mean_vector = class_data.mean(axis=0).values  \n",
    "    covariance_matrix = np.cov(class_data.T)  \n",
    "    \n",
    "    gaussian_params[class_label] = {\n",
    "        'mean': np.array(mean_vector, dtype=np.float64), \n",
    "        'covariance': np.array(covariance_matrix, dtype=np.float64)  # Ensure covariance is a float array\n",
    "    }\n",
    "    \n",
    "    prior_probabilities[class_label] = len(class_data) / total_samples\n",
    "\n",
    "# Define the multivariate Gaussian likelihood function\n",
    "def multivariate_gaussian_likelihood(x, mean, covariance):\n",
    "    \"\"\" Calculate the likelihood of x under the multivariate Gaussian distribution. \"\"\"\n",
    "    n = mean.shape[0]\n",
    "    diff = x - mean\n",
    "    \n",
    "    # Ensure the inputs are float64\n",
    "    diff = np.array(diff, dtype=np.float64)\n",
    "    \n",
    "    # Calculate the exponent\n",
    "    exponent = -0.5 * np.dot(diff.T, np.linalg.solve(covariance, diff))\n",
    "    \n",
    "    determinant = np.linalg.det(covariance)\n",
    "    likelihood = (1 / np.sqrt((2 * np.pi) ** n * determinant)) * np.exp(exponent)\n",
    "    return likelihood\n",
    "\n",
    "# Classify each test sample based on likelihood and prior\n",
    "predictions = []\n",
    "\n",
    "for _, row in test_data.iterrows():\n",
    "    sample = row.drop('Species').values  # Get the four-dimensional test sample (without the class label)\n",
    "    \n",
    "    # Ensure sample is a float array\n",
    "    sample = np.array(sample, dtype=np.float64)\n",
    "    \n",
    "    max_posterior = -float('inf')\n",
    "    predicted_class = None\n",
    "    \n",
    "    for class_label, params in gaussian_params.items():\n",
    "        likelihood = multivariate_gaussian_likelihood(sample, params['mean'], params['covariance'])\n",
    "        posterior = likelihood * prior_probabilities[class_label]\n",
    "        \n",
    "        if posterior > max_posterior:\n",
    "            max_posterior = posterior\n",
    "            predicted_class = class_label\n",
    "    \n",
    "    predictions.append(predicted_class)\n",
    "\n",
    "true_labels = test_data['Species'].values\n",
    "\n",
    "def confusion_matrix(true_labels, predicted_labels, classes):\n",
    "    matrix = np.zeros((len(classes), len(classes)), dtype=int)\n",
    "    \n",
    "    for true, pred in zip(true_labels, predicted_labels):\n",
    "        true_index = np.where(classes == true)[0][0]\n",
    "        pred_index = np.where(classes == pred)[0][0]\n",
    "        matrix[true_index][pred_index] += 1\n",
    "        \n",
    "    return matrix\n",
    "\n",
    "def accuracy(true_labels, predicted_labels):\n",
    "    correct_predictions = np.sum(true_labels == predicted_labels)\n",
    "    total_predictions = len(true_labels)\n",
    "    return correct_predictions / total_predictions\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, predictions, classes)\n",
    "accuracy_score_2 = accuracy(true_labels, predictions)\n",
    "\n",
    "confusion_df = pd.DataFrame(conf_matrix, index=classes, columns=classes)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_df)\n",
    "print(f\"Accuracy: {accuracy_score_2 * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>**Problem statement 3**</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_diff=math.sqrt(abs((accuracy_score_1-accuracy_score_2)**2)/2)\n",
    "print(accuracy_diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
